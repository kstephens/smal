
= SMAL - A (S)imple, (M)ark-sweep (AL)locator =

== Data Structure Overview ==

<code>smal_type</code> represents a user-data type of a fixed size, mark and free callbacks.

<code>smal_buffer</code> represents a <code>mmap()</code> region of <code>smal_buffer_size</code> aligned to <code>smal_buffer_size</code>.
Each <code>smal_buffer</code> is at the head of an <code>mmap()</code> region.

== Types ==

<code>smal_type</code> defines the size of objects and other characteristics that will be allocated from one or more <code>smal_buffer</code>s.
<code>mark_func</code> and <code>free_func</code> callback can be registered for each <code>smal_type</code>.

== Buffer Allocation ==

Each <code>smal_buffer</code> and its object allocation region are allocated from the OS via <code>mmap()</code> and is ensured to be aligned to <code>smal_buffer_size</code>.
This is achieved by <code>mmap()</code>ing <code>smal_buffer_size * 2</code> bytes and <code>munmap()</code>ing the unaligned portion.

== Object Allocation ==

Objects are parceled, on-demand, from a <code>smal_buffer</code>, by incrementing <code>alloc_ptr</code> by the <code>smal_type</code>'s fixed object size, <code>object_size</code>, starting at <code>begin_ptr</code> and terminating at <code>end_ptr</code>.
Unused objects that are returned to the <code>smal_buffer</code> are kept on its <code>free_list</code>.
<code>smal_buffers</code> without active objects are <code>munmap</code>ed and returned to the OS.

== Allocation Scheduling ==

Since SMAL does not compact or relocate objects during collection, it attempts to allocate from <code>smal_buffer</code> with the least amount of available objects (either unparceled or on the free list).  ''''THIS IS NOT IMPLEMENTED YET''''.

== Memory Alignment ==

=== Benefits ===

The alignment restrictions of <code>smal_buffers</code> ensures very minimal <code>mmap()</code>/OS-level fragmentation.
It also allows for very fast pointer to <code>smal_buffer</code> mapping, making SMAL
suitable for conservative and non-conservative collection.

=== Issues ===

SMAL cannot service allocations larger than <code>smal_buffer_size - sizeof(smal_buffer)</code>.

=== Characteristics ===

Every potential pointer maps to a unique <code>buffer_id</code>, computed
by dividing a <code>smal_buffer*</code> address by <code>smal_buffer_size</code>.

Since the <code>smal_buffer</code> header is always aligned to <code>smal_buffer_size</code>, 
it's trivial to map a potential object pointer to a potential <code>smal_buffer*</code> or its <code>buffer_id</code>.

A perfect hash table that maps <code>buffer_id</code>s to <code>smal_buffer*</code> is maintained.
A lack of an entry in this table, means that any potential
pointer mapping within the aligned <code>smal_buffer_size</code> region is not an object pointer allocated from a <code>smal_buffer</code>.

Because the table is guaranteed to be perfect and non-colliding, mapping an arbitrary pointer to a 
<code>smal_buffer</code> can be done in <code>O(1)</code> time, using a divide (or shift), a modulo and a vector index.
This operation takes 6 x86 instructions.

If a <code>smal_buffer*</code> can be found for a potential pointer, the pointer must also be within the <code>smal_buffer</code>'s region between
<code>begin_ptr</code> and <code>alloc_ptr</code> ) and must be aligned to <code>object_size</code>.
This operations takes 8 x86 instructions.

== Object Mark Bits ==

Each <code>smal_buffer</code> maintains a mark bitmap for each object parceled from it.
The mark bitmap is transient; it is <code>malloc()</code>ed and <code>free()</code>ed, on-demand, during <code>smal_collect()</code>.

A pointer's mark bitmap index is computed by dividing the difference between the pointer and its <code>smal_buffer*</code> with
the size of the objects (<code>object_size</code>) allocated from the <code>smal_buffer</code>.

If a pointer is known to be allocated and aligned, <code>smal_makr_ptr_exact()</code> can test the mark bit in 25. x86 instructions,
and mark the bit and recurse into the <code>mark_func</code> in another 6 x86 instructions.

== Mark-Sweep ==

The algorithms/data structures are as follows:

=== Mark a (potential) object ===

# Map potential object pointer to a potential <code>smal_buffer*</code> using <code>buffer_table</code>.
# Determine if object pointer within <code>smal_buffer</code> region where object allocations took place.
# Determine if object pointer has proper alignment to the head of the object allocation.
# Determine the mark bitmap offset.
# If object is not already marked, 
# mark the object in the bitmap and
# call the <code>smal_type</code>'s <code>mark_func</code> function.

=== Sweep ===

# For each <code>smal_buffer</code>:
# MORE HERE.

== Ecology ==

SMAL relies on <code>MAP_ANON</code> <code>mmap()</code>/<code>munmap()</code> and <code>malloc()</code>/<code>free()</code>, 
thus can co-exist with any other <code>mmap()</code>-based <code>malloc()</code>/<code>free()</code> library.

== Roots ==

The user must provide a <code>smal_mark_roots()</code> function.
This allows the user to configure support for different configurations:
* single-threaded
* multi-threaded
* conservative
* type-safe 
However, SMAL provides a simple, <code>smal_roots</code> package to explicitly declare root pointers on the C stack.

== Threads ==

SMAL supports a tiny <code>smal_thread</code> abstraction around <code>pthreads</code>.
The <code>smal_roots</code> package is thread-aware and thread-safe.  
The rest of the SMAL allocator is not yet thread-safe.

== TODO ==

* Support for weak references.
* Support for finalization.
* Full-thread safety.


